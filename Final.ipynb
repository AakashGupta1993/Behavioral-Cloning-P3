{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the data\n",
    "\n",
    "Download data from the web. I am using the sample data that is provided with the project resources. We can also make/create our own data using the simulator provided and then use it to train our model.\n",
    "\n",
    "Download and then extract the data. Further train using this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "#AWS\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "        #Unzip the downloaded file to get pickled data\n",
    "        zip = ZipFile('data.zip')\n",
    "        zip.extractall()\n",
    "\n",
    "# Downloading the training and test dataset.\n",
    "download('https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip', 'data.zip')\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file to get the path of the images along with the steering angles.\n",
    "\n",
    "Here I have augmented the sample data as sample data for turns is less as compared to data for straight line. Also left turn data is more as compared to right turn data. Therefore augmenting by flipping the images which have turns associated with them will help the model train better. Thus implemented the same in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/driving_log.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8ab55636eed4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#with open('../Behavioural Cloning Data/driving_log.csv') as csvfile:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/driving_log.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#with open('../data/driving_log_2.csv') as csvfile:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/driving_log.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lines =[]\n",
    "#with open('../Behavioural Cloning Data/driving_log.csv') as csvfile:\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "#with open('../data/driving_log_2.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "images=[]\n",
    "measurements=[]\n",
    "count=0\n",
    "for line in lines[1:]:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/' + filename\n",
    "    #current_path = source_path\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.imread(current_path)\n",
    "    #print(image.shape)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    if (abs(measurement)>0.1):\n",
    "        count=count+1\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement_flipped = -measurement\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "        if (count==1):\n",
    "            plt.imshow(image)\n",
    "            plt.xlabel('Normal Image')\n",
    "            plt.figure()\n",
    "            plt.imshow(image_flipped)\n",
    "            plt.xlabel('Flipped Image')\n",
    "    if (abs(measurement)>0.3):\n",
    "        count=count+1\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement_flipped = -measurement\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "        images.append(image)\n",
    "        measurements.append(measurement)\n",
    "        \n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "'''X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)'''\n",
    "print (X_train.shape)\n",
    "print(count)\n",
    "print(len(lines))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Model architecture summary is available at the end of the next block. It is implemented using model.summary() method.\n",
    "\n",
    "I have used model implemented by nvidia for autonomous vehicle for my project. I belive my model is similar yet very much different. The similarity is in the number of convolution layers in both the models. Rest almost everything is different, which includes dense layers, maxpool layers, number of filter in convolution layer. I have tuned the hyper-parameters to train my model.\n",
    "\n",
    "Before finalizing this model I also tried one another famous model - The LeNet achitecture. But the one I am using is working better so shifted to this one.\n",
    "### Cropping\n",
    "It is also seen that in track 1 some top portion of the images can be edited as it is basically comprised of trees and the hills. These things won't help that much to train our network. Thus cropping them and using the rest of the image to train the model.\n",
    "\n",
    "\n",
    "### Activation\n",
    "ELU activaion is used in the model to maintain the non-linearity.\n",
    "\n",
    "### Optimizer\n",
    "I have used AdamOptimizer as it is seen that it it changes learning rate efficiently as compared to others and help us train neural network faster and quicker.\n",
    "\n",
    "### Zero mean\n",
    "The sample data has been zero meaned as it helps to train the model faster and quickly as optimization is faster for this type of data \n",
    "\n",
    "\n",
    "### Training and test data set\n",
    "The sample data is split into the training and validation data set. It is split in the ratio of 8:2. It could also have been split in the ratio of 7:3. Both of these are good ratios for splitting the data into training and validation data set.\n",
    "\n",
    "I am training my model for 1 epoch so I am not using dropout as one of the techniques for overfitting of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 60, 320, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 56, 316, 6)    456         cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 28, 158, 6)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 28, 158, 6)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 24, 154, 16)   2416        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 12, 77, 16)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 12, 77, 16)    0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 8, 73, 18)     7218        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 8, 36, 18)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 36, 18)     0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 6, 34, 20)     3260        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 6, 17, 20)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 6, 17, 20)     0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 4, 15, 8)      1448        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 4, 15, 8)      0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 480)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 400)           192400      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 400)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 200)           80200       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 200)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 80)            16080       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 80)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             81          activation_8[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 303,559\n",
      "Trainable params: 303,559\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "#normalization\n",
    "model.add(Lambda(lambda x:x/255.0-0.5,input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((75,25),(0,0))))\n",
    "\n",
    "\n",
    "#Layer 1: Convolution\n",
    "model.add(Convolution2D(6, 5, 5,border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "\n",
    "#Layer 2: Convolution\n",
    "model.add(Convolution2D(16, 5, 5,border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "#Layer 3: Convolution\n",
    "model.add(Convolution2D(18, 5, 5,border_mode='valid'))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "#Layer 4: Convolution\n",
    "model.add(Convolution2D(20, 3, 3,border_mode='valid'))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Layer 5: Convolution\n",
    "model.add(Convolution2D(8, 3, 3,border_mode='valid'))\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "#Dense layer 1\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('elu'))\n",
    "#Dense layer 2\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('elu'))\n",
    "#Dense layer 3\n",
    "model.add(Dense(80))\n",
    "model.add(Activation('elu'))\n",
    "#Dense layer 4\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Train the model to get the model.h5 file.\n",
    "\n",
    "I have not used generators as my model was working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10446 samples, validate on 2612 samples\n",
      "Epoch 1/1\n",
      "10446/10446 [==============================] - 26s - loss: 0.0219 - val_loss: 0.0188\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train,y_train, validation_split=0.2, shuffle=True, nb_epoch=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Validation\n",
    "Once the training is done, validation in performed using the simulator provided in the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
